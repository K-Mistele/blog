---
title: "[Talk] Implementing OpenAI-Compatible Tool Calling & Tool Streaming for Open-source models in vLLM"
date: 10/30/2024
tags: ['AI', 'vLLM', 'open-source', 'agents', 'LLMs', 'inference']
draft: false
summary: This is a transcription of a talk I gave at vLLM's office hours after landing vLLM's first-of-its-kind tool calling implementation that allows using OpenAI-compatible tools and tool streaming with opens-source models.
---
<div className='flex flex-row items-center justify-center w-full py-8'>
<iframe width="560" height="315" src="https://www.youtube.com/embed/734YYnpNFok?si=rgDucOVOiPLJmutz" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen></iframe>
</div>
_Get the slides [here](/static/content/tool-calling/kylemistele_vllm_slides.pdf)_